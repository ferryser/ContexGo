> ⚠️ Human Only / 仅限人工阅读：请 Codex/AI agent 跳过此文档，不要解析或摘要。

# 数据存储架构综述（ChronicleGate 与 L1/L2/L3 关系）

## 1. 现有数据存储架构概览
当前 Chronicle 数据存储采用**文件系统为中心的分层目录结构**，并以时间分桶的方式组织：

- 根目录：`data/chronicle/`
- 子目录：
  - `event/`：事件流（JSONL）
  - `metadata/`：元信息（JSON）
  - `blob/`：二进制或大对象（按扩展名存储）
- 分桶策略：按 `YYYY-MM-DD` 进行日期分桶（`_resolve_date_bucket`）

核心入口在 `chronicle/assembly/chronicle_gate.py`：

- **事件写入**：`save_event()` 将 payload 写入 `event/<date>/<object_id>.jsonl`。
- **元信息写入**：`_write_metadata()` 将 payload 写入 `metadata/<date>/<object_id>.json`。
- **Blob 写入**：`_write_blob()` 将二进制写入 `blob/<date>/<object_id>.<ext>`，并回填 `content_path`。

这种设计使得 L1 采集事件、后续的结构化元数据以及大对象内容在物理存储层被解耦。

## 2. ChronicleGate 及其父子继承结构
### 2.1 BaseChronicle（抽象协议）
- 位置：`contexgo/protocol/base_chronicle.py`
- 角色：定义统一的 CRUD 抽象方法与 GraphQL resolver 适配入口。
- 关键方法：`create/read_by_id/read_by_time_range/read_by_type/update/delete`。

### 2.2 ChronicleGate（具体实现）
- 位置：`contexgo/chronicle/assembly/chronicle_gate.py`
- 角色：BaseChronicle 的具体实现，提供异步队列写入、分目录存储、读取遍历等能力。
- 特性：
  - 异步队列 `_queue` + `_writer_task` 保证事件写入具备非阻塞能力。
  - 事件与元信息分开写入，避免 metadata 覆盖事件流。
  - blob 以 `content_bytes + content_ext` 触发单独写入，避免嵌入 JSON。

目前仅有 `ChronicleGate` 作为 `BaseChronicle` 的子类，表明系统仍在单一存储实现阶段，方便后续扩展新的 Gate（如 DBGate、CloudGate）。

## 3. 与 L1 层的耦合与通信边界
### 3.1 L1 事件出口
- L1 传感器基类：`contexgo/chronicle/base_l1_sensor.py`
- 输出模型：`contexgo/protocol/context.py::RawContextProperties`
- L1 事件被编码为 `content_text`（JSON 字符串），并带 `object_id / create_time / source / content_format`。

### 3.2 ChronicleGate 与 L1 的耦合点
- `save_raw_context()` 直接接受 `RawContextProperties` 并调用 `save_event()`，**绕过** `ChronicleGate.create()` 逻辑。
- `WindowFocusSensor` 在 `_capture_impl()` 内直接调用 `save_raw_context()`，形成“采集 ➜ 写盘”的直链路。
- ChronicleGate 的 `_is_event()` 依赖 `content_type/context_type` 判断事件类别，而 L1 的 `RawContextProperties` 默认并不设置 `content_type`，说明 L1 与 ChronicleGate 的事件判断逻辑并非强绑定。

### 3.3 通信边界观察
- **边界偏薄**：L1 传感器直接调用存储函数（`save_raw_context`），相当于绕开统一的 Gate 抽象接口。
- **边界偏粗**：GraphQL Resolver 以 `ChronicleGate` 作为 context 注入，实现读写能力暴露给 API 层，但未显式区分 L1/L2 数据类型。

建议理解为：目前 L1 侧的“通信边界”较为工程化直连，尚未形成“统一存储服务层”的隔离。

## 4. 向 L2/L3 层扩展的演进展望
### 4.1 L2 语义层扩展方向
在 `contexgo/protocol/context.py` 中已有 L2 相关结构：
- `ExtractedData`：语义特征、关键词、实体等
- `ProcessedContext`：整合 `RawContextProperties` + `ExtractedData` + `Vectorize`

扩展路径建议：
1. **新增 ChronicleGate 子类**：如 `SemanticGate`，在 L2 写入时区分 `metadata` 与 `vector` 目录。
2. **在 ChronicleGate 内扩充类型分区**：基于 `context_type` 或 `content_type` 分层写入 L2/L3 数据。
3. **引入索引层**：为 L2/L3 检索增加轻量索引（如向量或实体索引），而 L1 继续保持原始事件流归档。

### 4.2 L3 认知层扩展方向
- L3 通常会聚合 `ProcessedContext` 为更高语义对象（任务、意图、叙事）。
- 可考虑新增 `knowledge/` 或 `memo/` 子目录，或采用独立存储系统（图谱/向量 DB）。
- ChronicleGate 可保持 L1/L2 的“可追溯性存档”，L3 交由更高阶存储（知识库、图数据库）承接。

## 5. 现有设计一致性检查
### 5.1 命名与字段一致性
- **object_id**：
  - L1 由 `BaseL1Sensor` 统一生成 UUIDv7，并保证内外一致。
  - ChronicleGate 在写 metadata/blob 时会补齐 object_id。整体一致性较高。
- **create_time**：
  - L1 事件携带时间戳，ChronicleGate 解析 `create_time` 进行分桶，逻辑一致。
- **content_type/context_type**：
  - ChronicleGate 通过 `content_type/context_type` 判定是否为 event。
  - L1 的 `RawContextProperties` 默认不设置 `content_type`，导致 Gate 的事件判断不一定与 L1 一致。
  - 但 L1 目前通过 `save_raw_context()` 直接写入 `event`，规避了上述判断差异。

### 5.2 存储结构一致性
- `event` 使用 `.jsonl` 但每个 object_id 文件只写一条记录，实际更像“单行 JSON”；若未来追加多条事件，需要统一约定是否为“多行事件流”。
- `metadata` 使用 `.json` 单对象存储，适合元信息更新但不支持历史版本追踪。

### 5.3 API 层一致性
- GraphQL schema 将 ChronicleGate 作为单一数据源，当前接口语义更偏向 L1/L0 存档数据，并未区分 L2/L3。
- 若未来 L2/L3 引入独立 Gate，需在 API 层明确区分查询入口与数据类型。

---

**结论**：现有 ChronicleGate + L1 设计已经形成可追溯的“原始信号存档层”，但在跨层通信边界上仍偏直连。下一步可通过增加 Gate 子类或类型分区，逐步扩展至 L2/L3 语义与认知存储，而不破坏 L1 的时序归档特性。
