# ContexGo L1 Protocol: Event Schema & Time Window Architecture

> **Philosophy:** Capture Signals, Containerize Time, Serialize Attention.
> **核心哲学:** 捕捉信号，时间为器，注意力为流。

---

## Part 1: Event Schema Specification (事件协议规范)

### 1. 核心抽象 (Core Abstraction)

系统遵循 **“信封模式” (Envelope Pattern)**。所有数据流均被封装为统一的原子事件结构。

**公式:** `Event = Header (路由层) + Payload (业务层)`

#### A. Header (固定区)
无论事件类型如何（心跳、文件修改、窗口活跃），以下字段永远存在且格式固定。用于分布式系统的索引、同步与去重。

* **uuid (ID):** 唯一标识符。
    * *策略:* 使用 UUIDv7 (包含时间戳信息的 UUID)，或 `Hash(Timestamp + DeviceID + Source)`。天然按时间排序且全局唯一。
* **timestamp (时间):** UTC 时间戳 (float/int)。
* **device_id (设备):** 物理位置标识 (e.g., "LivingRoom-PC")。*注意：不包含 UserID，租户隔离由同步层处理。*
* **type (类型):** 枚举字符串 (snake_case)，决定系统如何解析 Payload。

#### B. Payload (数据区)
一个多态的 JSON/Dict 对象。根据 `type` 的不同携带特定的业务数据。

---

### 2. 事件分类定义 (Event Taxonomy)

#### 2.1 input_metric (脉冲流)
* **定义:** 描述“用户此时此刻的投入度”。
* **触发机制:** 1Hz 周期性采样 (1秒1次)。
* **去噪策略:**
    1.  **静默丢弃 (Silence Drop):** 若 `input == 0`，不生成事件（默认视为 Idle）。
    2.  **饱和截断 (Saturation Clipping):** 设定 `MAX_INTENSITY` 阈值，防止高 APM 操作（如游戏）扭曲统计数据。
* **Payload 结构:**
    ```json
    {
      "keyboard_hits": 12,      // 饱和截断后的击键数
      "mouse_pixels": 800,      // 鼠标移动距离
      "mouse_clicks": 2,        // 点击次数
      "active_app_hash": "a1b2" // (可选) 用于后续校验是否与 window_focus 一致
    }
    ```

#### 2.2 window_focus (离散流)
* **定义:** 描述“用户注意力的锚点位置”。
* **触发机制:** 监听操作系统窗口回调 (Hook)，即刻触发。
* **价值:** 时间轴切割的核心依据。
* **Payload 结构:**
    ```json
    {
      "app_name": "Google Chrome",
      "window_title": "ContexGo Architecture - Google Docs",
      "url": "[https://docs.google.com/](https://docs.google.com/)...", // 仅在浏览器环境下存在，结构化程度最高
      "process_id": 1234
    }
    ```

#### 2.3 desktop_snapshot (高频视觉流)
* **定义:** 描述“用户看到的具体语义内容”。
* **触发机制:**
    1.  **视觉驻留 (Dwell):** 监测到 `window_focus` 变更后，倒计时 N 秒（如 2s）无新动作时触发。
    2.  **保底/高频采样 (Timer):** 用户自定义周期（推荐 10s - 20s），用于捕捉长内容的滚动浏览过程。
* **去重优化:** 计算当前屏幕的 **pHash (感知哈希)**。若 `Current_Hash == Last_Saved_Hash`，则丢弃或仅更新时间戳，避免存储重复图片。
* **Smart Sensor 设计:** 视为“文件名-词元对”。在资源允许时，OCR 结果可作为 Sensor 的一部分直接存入。
* **Payload 结构:**
    ```json
    {
      "file_path": "2025/12/20/img_100105.webp", // 图片存储路径 (滚动日志，短期存储)
      "timestamp": 1734705010.5,
      "trigger_source": "dwell",               // 枚举: "dwell"(驻留), "timer"(周期)
      "image_hash": "f0a1b2c3...",             // 核心: 用于下一帧对比去重
      "ocr_tokens": ["import", "class", "..."] // (可选) 异步填充的语义词元，支持即时索引
    }
    ```

#### 2.4 clipboard_update (显式意图流)
* **定义:** 描述“用户显式提取的高价值信息”。
* **触发机制:** 监听系统剪贴板变更消息。
* **隐私安全:** 必须通过正则 (Regex) 过滤掉密码管理器、私钥等敏感格式，敏感内容不落盘。
* **Payload 结构:**
    ```json
    {
      "content_type": "text",      // 枚举: "text", "image", "file_list"
      "content_preview": "def...", // 截取前 200 字符，用于快速预览
      "content_hash": "e5d4...",   // 用于内容去重
      "source_app": "VSCode"       // 从哪个应用复制的
    }
    ```

#### 2.5 system_lifecycle (边界流)
* **定义:** 描述“物理会话的绝对边界”。
* **触发机制:** 锁屏、解锁、休眠、唤醒。
* **价值:** 最高优先级的“切刀”，强制结束当前的 Task Session (任务会话)。
* **Payload 结构:**
    ```json
    {
      "action": "lock",           // 枚举: "lock", "unlock", "suspend", "resume"
      "trigger": "user_action"    // 枚举: "user_action", "timeout"
    }
    ```

---
# ContexGo L1 Protocol: Time Window Architecture (Updated)

> **Philosophy:** Containerize Time, Serialize Attention.
> **核心哲学:** 时间是容器，注意力是流。

---

## 1. 核心设计理念 (Architectural Philosophy)

**时间窗口 (Time Window)** 是系统进行持久化存储、分布式同步 (CRDT) 和 L2 认知计算的最小**原子单元**。它不应被视为一个简单的“事件垃圾桶”，而应被视为一段 **“多轨道的非线性编辑磁带”**。

### 1.1 物理视图 vs. 逻辑视图
系统设计通过双重视图解决“存储切片”与“任务连续性”之间的矛盾：

* **物理视图 (The Container):**
    * 采用 **5分钟 (300秒)** 的固定粒度。
    * 严格遵循 **左闭右开 $[t_{start}, t_{end})$** 的数学区间。
    * **目的:** 确保分布式环境下 ID 的确定性 (Determinism) 和同步的高效性。
* **逻辑视图 (The Flow):**
    * 内部承载的是 **注意力跨度 (Focus Spans)**。
    * 跨度是连续的，可能会跨越窗口边界。
    * **目的:** 还原人类工作的真实心流状态。

### 1.2 分层架构：基底与覆盖 (Base & Overlay)
一个时间窗口由两层数据构成：
1. **基底层 (Base Layer):** 连续填满时间轴的注意力状态 (FocusSpan)，要求 **无缝隙 (Gapless)**。
2. **覆盖层 (Overlay Layer):** 离散发生的高价值点状事件 (Snapshot/Clipboard)，具有 **稀疏性 (Sparse)**。

---

## 2. 数据结构抽象 (Data Structure Abstraction)

### 2.1 基底层：FocusSpan (注意力跨度)
这是时间窗口的一等公民。它将 `window_focus` (位置) 与 `input_metric` (强度) 融合为一个单一实体。

**定义:** 一段连续的、上下文同构的用户行为片段。

* **属性 I: 身份 (Identity)**
    * `App Name` & `Window Title`: 此时此刻用户“在哪里”。
    * `URL`: 结构化的互联网锚点 (若有)。
* **属性 II: 物理交互状态 (State)**
    * 基于输入频率和视觉变化的物理分类，描述“如何交互”而非“在做什么”：
        * **HIGH_INPUT (强交互):** 键盘/点击密集，输入强度超过阈值。
        * **NAVIGATION (弱交互):** 输入低，主要是鼠标移动、滚动或翻页产生的视觉变化。
        * **PASSIVE (被动消费):** 无物理输入但画面在剧烈变动（如视频、会议）。
        * **IDLE (静态/静止):** 无输入且画面静止。这是 L2 判断“假性聚焦”或“深层思考”的关键依据。
* **属性 III: 能量 (Energy)**
    * `Intensity Score`: 该片段内的累积活跃度积分。

### 2.2 覆盖层：Discrete Events (离散事件)
这些事件依附于时间轴，通过时间戳与 `FocusSpan` 建立**外键关联**。

* **Visual Track (视觉轨):** `desktop_snapshot` 列表。
    * *策略:* 全量保留。消费时进行基于权重的“关键帧提取”。
* **Intent Track (意图轨):** `clipboard_update` 列表。
    * *策略:* 显式意图，不可压缩，全量索引。
* **Boundary Track (边界轨):** `system_lifecycle` 列表。
    * *策略:* 用于标记物理会话的强制中断 (如锁屏)。

---

## 3. 聚合逻辑 (Aggregation Logic)

L1 聚合器 (Aggregator) 的工作是将原始的 Event 流 **"注解" (Annotate)** 到时间轴上。

### 3.1 注解流程 (The Annotation Pipeline)
1. **锚定 (Anchor):** 以 `window_focus` 事件为切刀，将 5 分钟切分为若干原始片段。
2. **挂载 (Mount):** 将 1Hz 的 `input_metric` 脉冲流分配给对应片段，计算 `Intensity Score`。
3. **定性 (Qualify):** 根据 Intensity 和 Visual Change Rate，决定片段的物理交互状态。
4. **关联 (Link):** 将 `desktop_snapshot` 和 `clipboard_update` 按时间戳挂载到最近的片段上。

### 3.2 缝合机制 (The Stitching Mechanism)
系统采用 **"L1 切分 (Sharding) -> L2 缝合 (Stitching)"** 模式解决任务切碎问题：

* **L1 (存储时):** 在 05:00 强制切断。Window A 存储任务“头部”，Window B 存储“尾部”。
* **L2 (读取时):** 若 $Window_A.last\_span$ 与 $Window_B.first\_span$ 的身份属性高度相似，则逻辑合并为长 `FocusSpan`。

---

## 4. 可组合性与压缩 (Composability & Compression)

设计必须支持 **向量化合并 (Vectorized Merging)**，以便 L2 将多个窗口压缩喂给大模型。

### 4.1 连续轨道的合并 (Concatenation)
* **算法:** `List Extension` 配合缝合机制。
* **结果:** 碎片化时间片转为连贯的“任务流”。

### 4.2 离散轨道的合并 (Sampling)
* **Intent Track:** 直接追加 (Append)，保留全量信息。
* **Visual Track:** **智能降维 (Smart Sampling)**。
    * **评分算法:** $Score = w_1(InputIntensity) + w_2(IsDwelled) + w_3(VisualUniqueness)$。
    * **Top-K:** 仅提取分数最高的 K 张作为视觉摘要。

---

## 5. 总结 (Summary)

本设计将时间窗口定义为 **“携带注解的注意力流容器”**。

* 它通过 **FocusSpan** 保留了微观交互质感。
* 它通过 **物理状态标签 (InteractionState)** 诚实记录 OS 焦点事实，将语义解释权留给 L2。
* 它实现了存储规整性与逻辑连续性的统一，是连接 L0 物理信号与 L2 认知洞察的桥梁。

```python
class InteractionState(str, Enum):
    # 纯粹基于输入频率和视觉变化的物理分类
    HIGH_INPUT = "high_input"   # 键盘/点击密集
    NAVIGATION = "navigation"   # 主要是鼠标移动/滚动
    PASSIVE    = "passive"      # 无输入但画面在动 (视频/会议)
    IDLE       = "idle"         # 无输入且画面静止

@dataclass
class FocusSpan:
    start_offset: int
    duration: int
    app_name: str
    window_title: str
    url: Optional[str]
    intensity_score: float
    state: InteractionState     # 描述"如何交互"，而不是"在做什么"
    attached_events: List[DiscreteEvent]

1. 完备的 L1 资产清单
原子事件协议 (Event Schema): 定义了 5 种核心物理信号（Input, Focus, Snapshot, Clipboard, Lifecycle）的数据封包格式。

物理存储模型: 确定了以 5 分钟为周期的“桶”结构，以及左闭右开的数学区间，解决了数据持久化和同步的基石问题。

注意力切片逻辑 (FocusSpan): 实现了将离散事件“注解”到连续时间轴的技术路径，保留了物理交互状态（Active/Static）。

数据生命周期策略: 确定了“高频采样 + 感知哈希去重 + 滚动日志存储”的视觉数据处理方案。